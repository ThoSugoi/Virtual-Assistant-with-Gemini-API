{"ast":null,"code":"var _jsxFileName = \"E:\\\\H\\u1ECDc t\\u1EADp\\\\College\\\\CRP\\\\project\\\\Virtual-Assistant-with-Gemini-API-1\\\\fe\\\\src\\\\components\\\\VoiceRecorder.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst VoiceRecorder = ({\n  onRecordingComplete\n}) => {\n  _s();\n  const [isRecording, setIsRecording] = useState(false);\n  const [currentFrame, setCurrentFrame] = useState(0);\n  const mediaRecorder = useRef(null);\n  const startTime = useRef(0);\n  const animationInterval = useRef(null);\n  useEffect(() => {\n    if (isRecording) {\n      animationInterval.current = setInterval(() => {\n        setCurrentFrame(prev => prev >= 4 ? 1 : prev + 1);\n      }, 250);\n    } else {\n      if (animationInterval.current) {\n        clearInterval(animationInterval.current);\n      }\n      setCurrentFrame(0);\n    }\n    return () => {\n      if (animationInterval.current) {\n        clearInterval(animationInterval.current);\n      }\n    };\n  }, [isRecording]);\n  const startRecording = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      mediaRecorder.current = new MediaRecorder(stream);\n      const audioChunks = [];\n      mediaRecorder.current.ondataavailable = event => {\n        audioChunks.push(event.data);\n      };\n      mediaRecorder.current.onstop = async () => {\n        const duration = (Date.now() - startTime.current) / 1000;\n        const audioBlob = new Blob(audioChunks, {\n          type: 'audio/wav'\n        });\n\n        // Create form data with audio file\n        const formData = new FormData();\n        formData.append('file', audioBlob, 'recording.wav');\n        try {\n          // Send to transcription endpoint\n          const response = await fetch('http://127.0.0.1:5000/transcribe', {\n            method: 'POST',\n            body: formData\n          });\n          const transcription = await response.text();\n          onRecordingComplete(duration, transcription);\n        } catch (error) {\n          console.error('Transcription error:', error);\n          onRecordingComplete(duration, \"Error transcribing audio\");\n        }\n        stream.getTracks().forEach(track => track.stop());\n      };\n      startTime.current = Date.now();\n      mediaRecorder.current.start();\n      setIsRecording(true);\n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n    }\n  };\n  const stopRecording = () => {\n    if (mediaRecorder.current && isRecording) {\n      mediaRecorder.current.stop();\n      setIsRecording(false);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"button\", {\n    onMouseDown: startRecording,\n    onMouseUp: stopRecording,\n    onMouseLeave: stopRecording,\n    style: {\n      padding: \"0\",\n      borderRadius: \"4px\",\n      backgroundColor: isRecording ? \"#dc3545\" : \"#6c757d\",\n      border: \"none\",\n      cursor: \"pointer\",\n      transition: \"background-color 0.3s ease\",\n      display: \"flex\",\n      alignItems: \"center\",\n      justifyContent: \"center\",\n      width: \"44px\",\n      height: \"44px\",\n      overflow: \"hidden\"\n    },\n    children: /*#__PURE__*/_jsxDEV(\"img\", {\n      src: currentFrame === 0 ? \"/mic.png\" : `/mic${currentFrame}.png`,\n      alt: \"Microphone\",\n      style: {\n        width: \"100%\",\n        height: \"100%\",\n        padding: \"8px\",\n        objectFit: \"contain\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 103,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 84,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceRecorder, \"W6fIdwXdf+sQZJE/dIQHBaW4z6Y=\");\n_c = VoiceRecorder;\nexport default VoiceRecorder;\nvar _c;\n$RefreshReg$(_c, \"VoiceRecorder\");","map":{"version":3,"names":["React","useState","useRef","useEffect","jsxDEV","_jsxDEV","VoiceRecorder","onRecordingComplete","_s","isRecording","setIsRecording","currentFrame","setCurrentFrame","mediaRecorder","startTime","animationInterval","current","setInterval","prev","clearInterval","startRecording","stream","navigator","mediaDevices","getUserMedia","audio","MediaRecorder","audioChunks","ondataavailable","event","push","data","onstop","duration","Date","now","audioBlob","Blob","type","formData","FormData","append","response","fetch","method","body","transcription","text","error","console","getTracks","forEach","track","stop","start","stopRecording","onMouseDown","onMouseUp","onMouseLeave","style","padding","borderRadius","backgroundColor","border","cursor","transition","display","alignItems","justifyContent","width","height","overflow","children","src","alt","objectFit","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["E:/Học tập/College/CRP/project/Virtual-Assistant-with-Gemini-API-1/fe/src/components/VoiceRecorder.tsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from 'react';\r\n\r\ninterface VoiceRecorderProps {\r\n  onRecordingComplete: (duration: number, transcript: string) => void;\r\n}\r\n\r\nconst VoiceRecorder: React.FC<VoiceRecorderProps> = ({ onRecordingComplete }) => {\r\n  const [isRecording, setIsRecording] = useState(false);\r\n  const [currentFrame, setCurrentFrame] = useState(0);\r\n  const mediaRecorder = useRef<MediaRecorder | null>(null);\r\n  const startTime = useRef<number>(0);\r\n  const animationInterval = useRef<NodeJS.Timeout | null>(null);\r\n\r\n  useEffect(() => {\r\n    if (isRecording) {\r\n      animationInterval.current = setInterval(() => {\r\n        setCurrentFrame(prev => prev >= 4 ? 1 : prev + 1);\r\n      }, 250);\r\n    } else {\r\n      if (animationInterval.current) {\r\n        clearInterval(animationInterval.current);\r\n      }\r\n      setCurrentFrame(0);\r\n    }\r\n\r\n    return () => {\r\n      if (animationInterval.current) {\r\n        clearInterval(animationInterval.current);\r\n      }\r\n    };\r\n  }, [isRecording]);\r\n\r\n  const startRecording = async () => {\r\n    try {\r\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n      mediaRecorder.current = new MediaRecorder(stream);\r\n      const audioChunks: Blob[] = [];\r\n\r\n      mediaRecorder.current.ondataavailable = (event) => {\r\n        audioChunks.push(event.data);\r\n      };\r\n\r\n      mediaRecorder.current.onstop = async () => {\r\n        const duration = (Date.now() - startTime.current) / 1000;\r\n        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\r\n        \r\n        // Create form data with audio file\r\n        const formData = new FormData();\r\n        formData.append('file', audioBlob, 'recording.wav');\r\n\r\n        try {\r\n          // Send to transcription endpoint\r\n          const response = await fetch('http://127.0.0.1:5000/transcribe', {\r\n            method: 'POST',\r\n            body: formData,\r\n          });\r\n          \r\n          const transcription = await response.text();\r\n          onRecordingComplete(duration, transcription);\r\n        } catch (error) {\r\n          console.error('Transcription error:', error);\r\n          onRecordingComplete(duration, \"Error transcribing audio\");\r\n        }\r\n        \r\n        stream.getTracks().forEach(track => track.stop());\r\n      };\r\n\r\n      startTime.current = Date.now();\r\n      mediaRecorder.current.start();\r\n      setIsRecording(true);\r\n    } catch (error) {\r\n      console.error('Error accessing microphone:', error);\r\n    }\r\n  };\r\n\r\n  const stopRecording = () => {\r\n    if (mediaRecorder.current && isRecording) {\r\n      mediaRecorder.current.stop();\r\n      setIsRecording(false);\r\n    }\r\n  };\r\n\r\n  return (\r\n    <button\r\n      onMouseDown={startRecording}\r\n      onMouseUp={stopRecording}\r\n      onMouseLeave={stopRecording}\r\n      style={{\r\n        padding: \"0\",\r\n        borderRadius: \"4px\",\r\n        backgroundColor: isRecording ? \"#dc3545\" : \"#6c757d\",\r\n        border: \"none\",\r\n        cursor: \"pointer\",\r\n        transition: \"background-color 0.3s ease\",\r\n        display: \"flex\",\r\n        alignItems: \"center\",\r\n        justifyContent: \"center\",\r\n        width: \"44px\",\r\n        height: \"44px\",\r\n        overflow: \"hidden\"\r\n      }}\r\n    >\r\n      <img \r\n        src={currentFrame === 0 ? \"/mic.png\" : `/mic${currentFrame}.png`}\r\n        alt=\"Microphone\"\r\n        style={{ \r\n          width: \"100%\",\r\n          height: \"100%\",\r\n          padding: \"8px\",\r\n          objectFit: \"contain\"\r\n        }} \r\n      />\r\n    </button>\r\n  );\r\n};\r\n\r\nexport default VoiceRecorder;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAM3D,MAAMC,aAA2C,GAAGA,CAAC;EAAEC;AAAoB,CAAC,KAAK;EAAAC,EAAA;EAC/E,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACU,YAAY,EAAEC,eAAe,CAAC,GAAGX,QAAQ,CAAC,CAAC,CAAC;EACnD,MAAMY,aAAa,GAAGX,MAAM,CAAuB,IAAI,CAAC;EACxD,MAAMY,SAAS,GAAGZ,MAAM,CAAS,CAAC,CAAC;EACnC,MAAMa,iBAAiB,GAAGb,MAAM,CAAwB,IAAI,CAAC;EAE7DC,SAAS,CAAC,MAAM;IACd,IAAIM,WAAW,EAAE;MACfM,iBAAiB,CAACC,OAAO,GAAGC,WAAW,CAAC,MAAM;QAC5CL,eAAe,CAACM,IAAI,IAAIA,IAAI,IAAI,CAAC,GAAG,CAAC,GAAGA,IAAI,GAAG,CAAC,CAAC;MACnD,CAAC,EAAE,GAAG,CAAC;IACT,CAAC,MAAM;MACL,IAAIH,iBAAiB,CAACC,OAAO,EAAE;QAC7BG,aAAa,CAACJ,iBAAiB,CAACC,OAAO,CAAC;MAC1C;MACAJ,eAAe,CAAC,CAAC,CAAC;IACpB;IAEA,OAAO,MAAM;MACX,IAAIG,iBAAiB,CAACC,OAAO,EAAE;QAC7BG,aAAa,CAACJ,iBAAiB,CAACC,OAAO,CAAC;MAC1C;IACF,CAAC;EACH,CAAC,EAAE,CAACP,WAAW,CAAC,CAAC;EAEjB,MAAMW,cAAc,GAAG,MAAAA,CAAA,KAAY;IACjC,IAAI;MACF,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzEZ,aAAa,CAACG,OAAO,GAAG,IAAIU,aAAa,CAACL,MAAM,CAAC;MACjD,MAAMM,WAAmB,GAAG,EAAE;MAE9Bd,aAAa,CAACG,OAAO,CAACY,eAAe,GAAIC,KAAK,IAAK;QACjDF,WAAW,CAACG,IAAI,CAACD,KAAK,CAACE,IAAI,CAAC;MAC9B,CAAC;MAEDlB,aAAa,CAACG,OAAO,CAACgB,MAAM,GAAG,YAAY;QACzC,MAAMC,QAAQ,GAAG,CAACC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGrB,SAAS,CAACE,OAAO,IAAI,IAAI;QACxD,MAAMoB,SAAS,GAAG,IAAIC,IAAI,CAACV,WAAW,EAAE;UAAEW,IAAI,EAAE;QAAY,CAAC,CAAC;;QAE9D;QACA,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;QAC/BD,QAAQ,CAACE,MAAM,CAAC,MAAM,EAAEL,SAAS,EAAE,eAAe,CAAC;QAEnD,IAAI;UACF;UACA,MAAMM,QAAQ,GAAG,MAAMC,KAAK,CAAC,kCAAkC,EAAE;YAC/DC,MAAM,EAAE,MAAM;YACdC,IAAI,EAAEN;UACR,CAAC,CAAC;UAEF,MAAMO,aAAa,GAAG,MAAMJ,QAAQ,CAACK,IAAI,CAAC,CAAC;UAC3CxC,mBAAmB,CAAC0B,QAAQ,EAAEa,aAAa,CAAC;QAC9C,CAAC,CAAC,OAAOE,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,sBAAsB,EAAEA,KAAK,CAAC;UAC5CzC,mBAAmB,CAAC0B,QAAQ,EAAE,0BAA0B,CAAC;QAC3D;QAEAZ,MAAM,CAAC6B,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;MACnD,CAAC;MAEDvC,SAAS,CAACE,OAAO,GAAGkB,IAAI,CAACC,GAAG,CAAC,CAAC;MAC9BtB,aAAa,CAACG,OAAO,CAACsC,KAAK,CAAC,CAAC;MAC7B5C,cAAc,CAAC,IAAI,CAAC;IACtB,CAAC,CAAC,OAAOsC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;IACrD;EACF,CAAC;EAED,MAAMO,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAI1C,aAAa,CAACG,OAAO,IAAIP,WAAW,EAAE;MACxCI,aAAa,CAACG,OAAO,CAACqC,IAAI,CAAC,CAAC;MAC5B3C,cAAc,CAAC,KAAK,CAAC;IACvB;EACF,CAAC;EAED,oBACEL,OAAA;IACEmD,WAAW,EAAEpC,cAAe;IAC5BqC,SAAS,EAAEF,aAAc;IACzBG,YAAY,EAAEH,aAAc;IAC5BI,KAAK,EAAE;MACLC,OAAO,EAAE,GAAG;MACZC,YAAY,EAAE,KAAK;MACnBC,eAAe,EAAErD,WAAW,GAAG,SAAS,GAAG,SAAS;MACpDsD,MAAM,EAAE,MAAM;MACdC,MAAM,EAAE,SAAS;MACjBC,UAAU,EAAE,4BAA4B;MACxCC,OAAO,EAAE,MAAM;MACfC,UAAU,EAAE,QAAQ;MACpBC,cAAc,EAAE,QAAQ;MACxBC,KAAK,EAAE,MAAM;MACbC,MAAM,EAAE,MAAM;MACdC,QAAQ,EAAE;IACZ,CAAE;IAAAC,QAAA,eAEFnE,OAAA;MACEoE,GAAG,EAAE9D,YAAY,KAAK,CAAC,GAAG,UAAU,GAAG,OAAOA,YAAY,MAAO;MACjE+D,GAAG,EAAC,YAAY;MAChBf,KAAK,EAAE;QACLU,KAAK,EAAE,MAAM;QACbC,MAAM,EAAE,MAAM;QACdV,OAAO,EAAE,KAAK;QACde,SAAS,EAAE;MACb;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACI,CAAC;AAEb,CAAC;AAACvE,EAAA,CA5GIF,aAA2C;AAAA0E,EAAA,GAA3C1E,aAA2C;AA8GjD,eAAeA,aAAa;AAAC,IAAA0E,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}